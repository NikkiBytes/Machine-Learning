{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fad536105e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-fad536105e43>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(i, h, o, learning_rate, epochs, sample_train, sample_test, prediction_file)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fad536105e43>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(data, i_nodes, o_nodes, epoch, alpha, prediction)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mi_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_pred\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "#Nichollette Acosta\n",
    "\n",
    "#Neural Network using Stochastic Gradient Descent \n",
    "\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "i = 5\n",
    "h = 7\n",
    "o = 10\n",
    "\n",
    "learning_rate = 0.05\n",
    "epochs = 3\n",
    "sample_train = \"optdigits_raining.csv\"\n",
    "sample_test = \"optdigits_test.csv\"\n",
    "threshold = 0\n",
    "\n",
    "prediction = \"predictions.csv\"\n",
    "\n",
    "\n",
    "# activation function -\n",
    "# returns compiuted sigmoid activation value for a given input value\n",
    "\n",
    "def sigmoid_activation(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "\n",
    "def get_batch(X, batchSize):\n",
    "    # loop over dataset in mini-batches of given size\n",
    "    for i  in np.arange(0, X.shape[0], batchSize):\n",
    "        return (X[i:i +  batchSize]) # yield tuple of current batched data and label\n",
    "        \n",
    "def train_neural_network(data, i_nodes, o_nodes,epoch, alpha,prediction):\n",
    "    \n",
    "    #initialize a list to store the loss value for each epoch\n",
    "    lossHistory = []\n",
    "   \n",
    "    mu, sigma = 0, math.sqrt(1) # mean and std deviation\n",
    "    \n",
    "    #\n",
    "    # Initialize weight matrix such it has the same number of cols as our input features\n",
    "    syn0 = np.random.normal(mu,sigma, i_nodes)\n",
    "    \n",
    "    syn1 = np.random.normal(mu,sigma, o_nodes)\n",
    "    \n",
    "    batch_data = get_batch(data, epoch)\n",
    "    \n",
    "    \n",
    "    for e in range(epoch):\n",
    "        epochLoss = []\n",
    "        \n",
    "        for batch in batch_data:\n",
    "            \n",
    "            i_pred = sigmoid_activation(batch.dot(W))\n",
    "            \n",
    "            error = i_pred- batch\n",
    "            \n",
    "            \n",
    "            \n",
    "            gradient = batch.T.dot(error) / batch.shape[0]\n",
    "            \n",
    "            syn0 += alpha * gradient \n",
    "            \n",
    "            \n",
    "            \n",
    "            o_pred = sigmoid_activation(batch.dot(W))\n",
    "            \n",
    "            error = o_pred - batch\n",
    "            \n",
    "            loss = np.sum(error**2)\n",
    "            epochLoss.append(loss)\n",
    "            gradient = batch.T.dot(error) / batch.shape[0]\n",
    "            \n",
    "            syn1 += alpha * gradient \n",
    "\n",
    "    \n",
    "    \n",
    "    lossHistory.append(np.average(epochLoss))\n",
    "    \n",
    "    print(syn1)\n",
    "        \n",
    "        \n",
    "def main(i, h, o, learning_rate, epochs, sample_train, sample_test, prediction_file):\n",
    "    i_nodes = i\n",
    "    h_nodes = h\n",
    "    o_nodes = o \n",
    "    l_rate = learning_rate\n",
    "    epo = epochs\n",
    "    X_train = pd.read_csv(sample_train)\n",
    "    X_test = pd.read_csv(sample_test)\n",
    "    X_predict = prediction_file\n",
    "        \n",
    "        \n",
    "    train_neural_network(X_train, i_nodes, o_nodes, epo, l_rate,prediction)\n",
    "\n",
    "main(i,h,o,learning_rate, epochs, sample_train, sample_test, prediction)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

